#!/usr/bin/env python3
"""
GigaAM v3 Transcriber - REST API
–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π REST API –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ —Å –¥–æ—Å—Ç—É–ø–æ–º –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞
"""

import os
import sys
import uuid
import time
import asyncio
import shutil
import zipfile
import io
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional, List, Dict
from contextlib import asynccontextmanager

import aiofiles
from fastapi import (
    FastAPI, File, UploadFile, HTTPException, Depends,
    BackgroundTasks, status, Header, Request
)
from fastapi.responses import JSONResponse, FileResponse, StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

# –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
import warnings
warnings.filterwarnings("ignore", category=UserWarning)

# –ò–º–ø–æ—Ä—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞
from src.utils.pyannote_patch import apply_pyannote_patch
from src.core.model_loader import ModelLoader
from src.core.processor import TranscriptionProcessor
from src.utils.processing_stats import ProcessingStats
from src.utils.logger import setup_logger
from src.config import HF_TOKEN, SUPPORTED_FORMATS

# –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–∞—Ç—á
apply_pyannote_patch()

# ==================== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ====================

# –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ .env
import os
from pathlib import Path
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
env_path = Path(__file__).parent / '.env'
if env_path.exists():
    load_dotenv(env_path, override=False)

# API –∫–ª—é—á–∏
API_KEYS_FILE = Path(__file__).parent / os.getenv("API_KEYS_FILE", ".api_keys")
VALID_API_KEYS = set()

# –î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
UPLOAD_DIR = Path(__file__).parent / os.getenv("UPLOAD_DIR", "uploads")
RESULTS_DIR = Path(__file__).parent / os.getenv("RESULTS_DIR", "results")
UPLOAD_DIR.mkdir(exist_ok=True)
RESULTS_DIR.mkdir(exist_ok=True)

# –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è (–∏–∑ .env –∏–ª–∏ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
MAX_FILE_SIZE = int(os.getenv("MAX_FILE_SIZE", str(2 * 1024 * 1024 * 1024)))  # 2GB
MAX_CONCURRENT_TASKS = int(os.getenv("MAX_CONCURRENT_TASKS", "3"))
TASK_CLEANUP_HOURS = int(os.getenv("TASK_CLEANUP_HOURS", "24"))

# API –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
API_HOST = os.getenv("API_HOST", "127.0.0.1")
API_PORT = int(os.getenv("API_PORT", "8000"))
API_WORKERS = int(os.getenv("API_WORKERS", "2"))

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
model_loader = None
stats_manager = None
logger = None

# –•—Ä–∞–Ω–∏–ª–∏—â–µ –∑–∞–¥–∞—á (–≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Redis –∏–ª–∏ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö)
tasks_storage: Dict[str, dict] = {}

# –°–µ–º–∞—Ñ–æ—Ä –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á
processing_semaphore = None


# ==================== –ú–û–î–ï–õ–ò ====================

class TaskStatus(BaseModel):
    """–°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏"""
    task_id: str
    status: str  # pending, processing, completed, failed
    created_at: str
    started_at: Optional[str] = None
    completed_at: Optional[str] = None
    progress: int = 0  # 0-100
    filename: str
    file_size: int
    message: Optional[str] = None
    error: Optional[str] = None
    error_details: Optional[str] = None  # –ü–æ–ª–Ω—ã–π traceback –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏


class TaskResult(BaseModel):
    """–†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏"""
    task_id: str
    status: str
    filename: str
    transcription: Optional[str] = None
    transcription_with_timecodes: Optional[str] = None
    processing_time: Optional[float] = None
    media_duration: Optional[float] = None


class UploadResponse(BaseModel):
    """–û—Ç–≤–µ—Ç –Ω–∞ –∑–∞–≥—Ä—É–∑–∫—É —Ñ–∞–π–ª–∞"""
    task_id: str
    message: str
    filename: str
    file_size: int
    estimated_time: Optional[str] = None


class BatchUploadResponse(BaseModel):
    """–û—Ç–≤–µ—Ç –Ω–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É —Ñ–∞–π–ª–æ–≤"""
    tasks: List[UploadResponse]
    total_files: int
    message: str


class APIKeyCreate(BaseModel):
    """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ API –∫–ª—é—á–∞"""
    description: str = Field(..., min_length=3, max_length=100)


class APIKeyResponse(BaseModel):
    """–û—Ç–≤–µ—Ç —Å API –∫–ª—é—á–æ–º"""
    api_key: str
    description: str
    created_at: str


# ==================== –£–¢–ò–õ–ò–¢–´ ====================

def load_api_keys():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç API –∫–ª—é—á–∏ –∏–∑ —Ñ–∞–π–ª–∞"""
    global VALID_API_KEYS
    if API_KEYS_FILE.exists():
        with open(API_KEYS_FILE, 'r') as f:
            VALID_API_KEYS = set(line.strip() for line in f if line.strip())
    else:
        # –°–æ–∑–¥–∞–µ–º –ø–µ—Ä–≤—ã–π –∫–ª—é—á –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        default_key = f"gam_{uuid.uuid4().hex}"
        VALID_API_KEYS.add(default_key)
        save_api_keys()
        print(f"\n{'='*60}")
        print(f"–ü–ï–†–í–´–ô API –ö–õ–Æ–ß –°–û–ó–î–ê–ù:")
        print(f"  {default_key}")
        print(f"–°–æ—Ö—Ä–∞–Ω–∏—Ç–µ –µ–≥–æ –≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ–º –º–µ—Å—Ç–µ!")
        print(f"{'='*60}\n")


def save_api_keys():
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç API –∫–ª—é—á–∏ –≤ —Ñ–∞–π–ª"""
    with open(API_KEYS_FILE, 'w') as f:
        for key in VALID_API_KEYS:
            f.write(f"{key}\n")
    os.chmod(API_KEYS_FILE, 0o600)  # –¢–æ–ª—å–∫–æ –≤–ª–∞–¥–µ–ª–µ—Ü –º–æ–∂–µ—Ç —á–∏—Ç–∞—Ç—å


def verify_api_key(x_api_key: str = Header(..., alias="X-API-Key")) -> str:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç API –∫–ª—é—á"""
    if x_api_key not in VALID_API_KEYS:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="–ù–µ–≤–µ—Ä–Ω—ã–π API –∫–ª—é—á"
        )
    return x_api_key


def is_supported_format(filename: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞"""
    extensions = SUPPORTED_FORMATS[1].split()
    file_ext = Path(filename).suffix.lower()
    return any(file_ext == ext.replace('*', '') for ext in extensions)


def restore_tasks_from_results():
    """–í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–¥–∞—á–∞—Ö –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ API"""
    if not RESULTS_DIR.exists():
        return
    
    restored_count = 0
    for task_dir in RESULTS_DIR.iterdir():
        if not task_dir.is_dir():
            continue
        
        task_id = task_dir.name
        
        # –ò—â–µ–º –ª—é–±–æ–π txt —Ñ–∞–π–ª –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏–º–µ–Ω–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        txt_files = list(task_dir.glob("*.txt"))
        if not txt_files:
            continue
        
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Ñ–∞–π–ª (–Ω–µ timecodes)
        result_file = None
        for f in txt_files:
            if not f.name.endswith('_timecodes.txt'):
                result_file = f
                break
        
        if not result_file:
            continue
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
        filename_base = result_file.stem
        # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —á—Ç–æ —ç—Ç–æ –±—ã–ª –∞—É–¥–∏–æ —Ñ–∞–π–ª (–º–æ–∂–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å .ogg –∫–∞–∫ fallback)
        original_filename = filename_base + '.ogg'
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–∞
        created_timestamp = datetime.fromtimestamp(result_file.stat().st_ctime)
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø–∏—Å—å –æ –∑–∞–¥–∞—á–µ
        tasks_storage[task_id] = {
            'task_id': task_id,
            'status': 'completed',
            'created_at': created_timestamp.isoformat(),
            'started_at': created_timestamp.isoformat(),
            'completed_at': created_timestamp.isoformat(),
            'progress': 100,
            'filename': original_filename,
            'file_size': 0,  # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ
            'message': '–ó–∞–¥–∞—á–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ API'
        }
        
        restored_count += 1
    
    if restored_count > 0:
        logger.info(f"–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ {restored_count} –∑–∞–¥–∞—á –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")


async def cleanup_old_tasks():
    """–û—á–∏—â–∞–µ—Ç —Å—Ç–∞—Ä—ã–µ –∑–∞–¥–∞—á–∏ –∏ —Ñ–∞–π–ª—ã"""
    now = time.time()
    cutoff = now - (TASK_CLEANUP_HOURS * 3600)
    
    tasks_to_remove = []
    for task_id, task in tasks_storage.items():
        created_timestamp = datetime.fromisoformat(task['created_at']).timestamp()
        if created_timestamp < cutoff:
            tasks_to_remove.append(task_id)
            
            # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª—ã
            upload_path = UPLOAD_DIR / f"{task_id}_{task['filename']}"
            if upload_path.exists():
                upload_path.unlink()
            
            # –£–¥–∞–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            result_dir = RESULTS_DIR / task_id
            if result_dir.exists():
                shutil.rmtree(result_dir)
    
    for task_id in tasks_to_remove:
        del tasks_storage[task_id]
        logger.info(f"–û—á–∏—â–µ–Ω–∞ –∑–∞–¥–∞—á–∞ {task_id} (—Å—Ç–∞—Ä—à–µ {TASK_CLEANUP_HOURS}—á)")


async def process_transcription(task_id: str, file_path: Path, filename: str):
    """
    –§–æ–Ω–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
    
    Args:
        task_id: ID –∑–∞–¥–∞—á–∏
        file_path: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
        filename: –∏–º—è —Ñ–∞–π–ª–∞
    """
    async with processing_semaphore:
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø—É—Ç—å –∏ resolved –ø—É—Ç—å –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
            file_path_original = file_path
            file_path_resolved = file_path.resolve()
            
            # –õ–æ–≥–∏—Ä—É–µ–º –æ–±–∞ –ø—É—Ç–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            logger.debug(f"[{task_id}] –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–∞:")
            logger.debug(f"[{task_id}]   –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø—É—Ç—å: {file_path_original}")
            logger.debug(f"[{task_id}]   Resolved –ø—É—Ç—å: {file_path_resolved}")
            logger.debug(f"[{task_id}]   –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {file_path_original.exists()}")
            logger.debug(f"[{task_id}]   Resolved —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {file_path_resolved.exists()}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞ –ø—É—Ç–∏
            actual_file_path = None
            if file_path_resolved.exists():
                actual_file_path = file_path_resolved
            elif file_path_original.exists():
                actual_file_path = file_path_original
            else:
                # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Ñ–∞–π–ª –ø–æ –∏–º–µ–Ω–∏ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ uploads
                filename_only = file_path_original.name
                alternative_path = UPLOAD_DIR / filename_only
                logger.debug(f"[{task_id}]   –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø—É—Ç—å: {alternative_path}")
                logger.debug(f"[{task_id}]   –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {alternative_path.exists()}")
                
                if alternative_path.exists():
                    actual_file_path = alternative_path
                else:
                    # –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Ñ–∞–π–ª —á–µ—Ä–µ–∑ glob, —Ç–∞–∫ –∫–∞–∫ —Ñ–∞–π–ª –º–æ–∂–µ—Ç –µ—â–µ –Ω–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–ø–∏—Å–∞–Ω –Ω–∞ –¥–∏—Å–∫
                    # –∏ exists() –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å False, –Ω–æ glob –≤—Å–µ —Ä–∞–≤–Ω–æ –Ω–∞–π–¥–µ—Ç —Ñ–∞–π–ª
                    try:
                        files_in_dir = list(UPLOAD_DIR.glob(f"*{task_id}*"))
                        logger.debug(f"[{task_id}] –§–∞–π–ª—ã —Å task_id –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ uploads (—á–µ—Ä–µ–∑ glob): {[str(f) for f in files_in_dir]}")
                        
                        if files_in_dir:
                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                            found_file = files_in_dir[0]
                            logger.debug(f"[{task_id}] –ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª —á–µ—Ä–µ–∑ glob: {found_file}")
                            logger.debug(f"[{task_id}] –§–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç (–ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Å–ª–µ glob): {found_file.exists()}")
                            
                            # –î–∞–∂–µ –µ—Å–ª–∏ exists() –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç False, –ø—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ñ–∞–π–ª
                            # –í–æ–∑–º–æ–∂–Ω–æ, —Ñ–∞–π–ª –µ—â–µ –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è, –Ω–æ —É–∂–µ –¥–æ—Å—Ç—É–ø–µ–Ω —á–µ—Ä–µ–∑ glob
                            actual_file_path = found_file
                            logger.info(f"[{task_id}] –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∞–π–ª, –Ω–∞–π–¥–µ–Ω–Ω—ã–π —á–µ—Ä–µ–∑ glob (–º–æ–∂–µ—Ç –±—ã—Ç—å –µ—â–µ –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è)")
                        else:
                            error_msg = f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∏ –ø–æ –æ–¥–Ω–æ–º—É –∏–∑ –ø—É—Ç–µ–π:\n  - {file_path_original}\n  - {file_path_resolved}\n  - {alternative_path}"
                            logger.error(f"[{task_id}] {error_msg}")
                            
                            tasks_storage[task_id].update({
                                'status': 'failed',
                                'completed_at': datetime.now().isoformat(),
                                'error': error_msg,
                                'message': '–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω'
                            })
                            return
                    except Exception as e:
                        logger.debug(f"[{task_id}] –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é uploads: {e}")
                        error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Ñ–∞–π–ª–∞: {str(e)}"
                        logger.error(f"[{task_id}] {error_msg}")
                        tasks_storage[task_id].update({
                            'status': 'failed',
                            'completed_at': datetime.now().isoformat(),
                            'error': error_msg,
                            'message': '–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Ñ–∞–π–ª–∞'
                        })
                        return
            
            logger.debug(f"[{task_id}] –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É: {actual_file_path}")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
            tasks_storage[task_id]['status'] = 'processing'
            tasks_storage[task_id]['started_at'] = datetime.now().isoformat()
            tasks_storage[task_id]['progress'] = 5
            
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            output_dir = RESULTS_DIR / task_id
            output_dir.mkdir(exist_ok=True)
            
            # Callback –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            def progress_callback(stage: str, progress: float):
                if stage == 'conversion':
                    tasks_storage[task_id]['progress'] = int(5 + progress * 15)
                elif stage == 'transcription':
                    tasks_storage[task_id]['progress'] = int(20 + progress * 75)
            
            # –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä
            processor = TranscriptionProcessor(
                model_loader=model_loader,
                stats_manager=stats_manager,
                logger=lambda msg: logger.debug(f"[{task_id}] {msg}"),
                progress_callback=progress_callback
            )
            
            # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–∞ –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
            # –ï—Å–ª–∏ —Ñ–∞–π–ª –±—ã–ª –Ω–∞–π–¥–µ–Ω —á–µ—Ä–µ–∑ glob, –æ–Ω –º–æ–∂–µ—Ç –µ—â–µ –∑–∞–ø–∏—Å—ã–≤–∞—Ç—å—Å—è
            # –ü—Ä–æ–±—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ —Å –Ω–µ–±–æ–ª—å—à–æ–π –∑–∞–¥–µ—Ä–∂–∫–æ–π
            file_found = False
            for attempt in range(3):
                if actual_file_path.exists():
                    file_found = True
                    break
                else:
                    logger.debug(f"[{task_id}] –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}/3: —Ñ–∞–π–ª –µ—â–µ –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –∂–¥–µ–º 0.5 —Å–µ–∫...")
                    await asyncio.sleep(0.5)
            
            if not file_found:
                # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ glob
                files_in_dir = list(UPLOAD_DIR.glob(f"*{task_id}*"))
                if files_in_dir:
                    actual_file_path = files_in_dir[0]
                    logger.info(f"[{task_id}] –§–∞–π–ª –Ω–∞–π–¥–µ–Ω —á–µ—Ä–µ–∑ glob –ø–æ—Å–ª–µ –æ–∂–∏–¥–∞–Ω–∏—è: {actual_file_path}")
                    file_found = True
            
            if not file_found:
                error_msg = f"–§–∞–π–ª –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ—Å–ª–µ –æ–∂–∏–¥–∞–Ω–∏—è: {actual_file_path}"
                logger.error(f"[{task_id}] {error_msg}")
                tasks_storage[task_id].update({
                    'status': 'failed',
                    'completed_at': datetime.now().isoformat(),
                    'error': error_msg,
                    'message': '–§–∞–π–ª –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ—Å–ª–µ –æ–∂–∏–¥–∞–Ω–∏—è'
                })
                return
            
            logger.debug(f"[{task_id}] –§–∞–π–ª –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π: {actual_file_path}")
            try:
                file_size = actual_file_path.stat().st_size
                logger.debug(f"[{task_id}] –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size} –±–∞–π—Ç")
            except Exception as e:
                logger.warning(f"[{task_id}] –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {e}")
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–º –∫–æ–¥–µ —á–µ—Ä–µ–∑ executor
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(
                None,
                processor.process_file,
                str(actual_file_path),
                str(output_dir),
                0,
                1,
                filename  # –ü–µ—Ä–µ–¥–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
            )
            
            if result['success']:
                # –ß–∏—Ç–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                # –§–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º
                text_file = output_dir / f"{Path(filename).stem}.txt"
                timecode_file = output_dir / f"{Path(filename).stem}_timecodes.txt"
                
                transcription = ""
                transcription_timecoded = ""
                
                if text_file.exists():
                    async with aiofiles.open(text_file, 'r', encoding='utf-8') as f:
                        transcription = await f.read()
                
                if timecode_file.exists():
                    async with aiofiles.open(timecode_file, 'r', encoding='utf-8') as f:
                        transcription_timecoded = await f.read()
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–¥–∞—á—É
                tasks_storage[task_id].update({
                    'status': 'completed',
                    'completed_at': datetime.now().isoformat(),
                    'progress': 100,
                    'transcription': transcription,
                    'transcription_timecoded': transcription_timecoded,
                    'processing_time': result['total_time'],
                    'media_duration': result.get('media_duration', 0),
                    'message': '–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞'
                })
                
                logger.info(f"–ó–∞–¥–∞—á–∞ {task_id} —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ ({result['total_time']:.1f}—Å)")
                
            else:
                raise Exception("–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å")
                
        except Exception as e:
            import traceback
            error_traceback = traceback.format_exc()
            error_msg = str(e)
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–¥–∞—á–∏ {task_id}: {error_msg}")
            logger.debug(f"Traceback –¥–ª—è –∑–∞–¥–∞—á–∏ {task_id}:\n{error_traceback}")
            tasks_storage[task_id].update({
                'status': 'failed',
                'completed_at': datetime.now().isoformat(),
                'error': error_msg,
                'error_details': error_traceback,  # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª–Ω—ã–π traceback –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                'message': f'–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {error_msg}'
            })
        
        finally:
            # –£–¥–∞–ª—è–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
            # –ù–ï —É–¥–∞–ª—è–µ–º —Ñ–∞–π–ª, –µ—Å–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å - —Ñ–∞–π–ª –º–æ–∂–µ—Ç –ø–æ–Ω–∞–¥–æ–±–∏—Ç—å—Å—è –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–∏
            task_status = tasks_storage.get(task_id, {}).get('status', 'unknown')
            if task_status == 'completed':
                # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                paths_to_check = []
                if 'actual_file_path' in locals():
                    paths_to_check.append(actual_file_path)
                paths_to_check.append(file_path)
                if hasattr(file_path, 'resolve'):
                    paths_to_check.append(file_path.resolve())
                
                for path_to_check in paths_to_check:
                    if path_to_check and Path(path_to_check).exists():
                        try:
                            Path(path_to_check).unlink()
                            logger.debug(f"[{task_id}] –£–¥–∞–ª–µ–Ω —Ñ–∞–π–ª –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏: {path_to_check}")
                            break
                        except Exception as e:
                            logger.debug(f"[{task_id}] –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Ñ–∞–π–ª {path_to_check}: {e}")
            else:
                logger.debug(f"[{task_id}] –§–∞–π–ª –Ω–µ —É–¥–∞–ª–µ–Ω (—Å—Ç–∞—Ç—É—Å: {task_status}), –º–æ–∂–µ—Ç –ø–æ–Ω–∞–¥–æ–±–∏—Ç—å—Å—è –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–∏")


# ==================== LIFESPAN ====================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    global model_loader, stats_manager, logger, processing_semaphore
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    print("="*60)
    print("üöÄ –ó–∞–ø—É—Å–∫ GigaAM v3 Transcriber API")
    print("="*60)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ API –∫–ª—é—á–µ–π
    load_api_keys()
    
    # –õ–æ–≥–≥–µ—Ä
    logger = setup_logger()
    logger.info("API —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è...")
    
    # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    restore_tasks_from_results()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–∫–µ–Ω–∞
    if not HF_TOKEN or not HF_TOKEN.startswith("hf_"):
        logger.error("HuggingFace —Ç–æ–∫–µ–Ω –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω!")
        raise RuntimeError("–¢—Ä–µ–±—É–µ—Ç—Å—è –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å HF_TOKEN –≤ .env")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ GigaAM-v3...")
    model_loader = ModelLoader()
    success = model_loader.load_model(logger=logger.info)
    
    if not success:
        logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å!")
        raise RuntimeError("–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏")
    
    logger.info("–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats_manager = ProcessingStats()
    
    # –°–µ–º–∞—Ñ–æ—Ä –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∑–∞–¥–∞—á
    processing_semaphore = asyncio.Semaphore(MAX_CONCURRENT_TASKS)
    
    logger.info(f"API –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ (–º–∞–∫—Å. {MAX_CONCURRENT_TASKS} –∑–∞–¥–∞—á –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ)")
    print("‚úÖ API —Å–µ—Ä–≤–µ—Ä —É—Å–ø–µ—à–Ω–æ –∑–∞–ø—É—â–µ–Ω!")
    print("="*60)
    
    yield
    
    # –û—á–∏—Å—Ç–∫–∞
    logger.info("–û—Å—Ç–∞–Ω–æ–≤–∫–∞ API —Å–µ—Ä–≤–µ—Ä–∞...")
    print("\nüëã API —Å–µ—Ä–≤–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")


# ==================== –ü–†–ò–õ–û–ñ–ï–ù–ò–ï ====================

# Rate limiter
limiter = Limiter(key_func=get_remote_address)

app = FastAPI(
    title="GigaAM v3 Transcriber API",
    description="REST API –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –∞—É–¥–∏–æ –∏ –≤–∏–¥–µ–æ —Ñ–∞–π–ª–æ–≤ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ",
    version="3.0.0",
    lifespan=lifespan
)

app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # –í –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ —É–∫–∞–∑–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–æ–º–µ–Ω—ã
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ==================== –≠–ù–î–ü–û–ò–ù–¢–´ ====================

@app.get("/")
async def root():
    """–ö–æ—Ä–Ω–µ–≤–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç - –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–µ—Ä–≤–∏—Å–µ"""
    return {
        "service": "GigaAM v3 Transcriber API",
        "version": "3.0.0",
        "status": "running",
        "description": "REST API –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –∞—É–¥–∏–æ –∏ –≤–∏–¥–µ–æ —Ñ–∞–π–ª–æ–≤ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ",
        "endpoints": {
            "docs": {
                "swagger": "/docs",
                "redoc": "/redoc"
            },
            "health": "/health",
            "transcription": {
                "upload_single": "POST /api/v1/transcribe",
                "upload_batch": "POST /api/v1/transcribe/batch"
            },
            "tasks": {
                "list_all": "GET /api/v1/tasks",
                "get_status": "GET /api/v1/tasks/{task_id}",
                "get_result": "GET /api/v1/tasks/{task_id}/result",
                "delete": "DELETE /api/v1/tasks/{task_id}",
                "delete_all": "DELETE /api/v1/tasks?status=completed|failed|all"
            },
            "progress": {
                "single": "GET /api/v1/tasks/{task_id}",
                "batch": "GET /api/v1/tasks/progress/batch?task_ids=id1,id2,id3"
            },
            "download": {
                "single": "GET /api/v1/tasks/{task_id}/download?format=txt|timecodes",
                "batch": "GET /api/v1/download-batch?task_ids=id1,id2&format=txt|timecodes"
            }
        }
    }


@app.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞"""
    return {
        "status": "healthy",
        "model_loaded": model_loader is not None and model_loader.is_loaded(),
        "active_tasks": sum(1 for t in tasks_storage.values() if t['status'] == 'processing'),
        "total_tasks": len(tasks_storage),
        "uptime": "running"
    }




@app.post(
    "/api/v1/transcribe",
    response_model=UploadResponse,
    status_code=status.HTTP_202_ACCEPTED,
    dependencies=[Depends(verify_api_key)]
)
@limiter.limit("10/minute")
async def upload_file(
    request: Request,
    background_tasks: BackgroundTasks,
    file: UploadFile = File(..., description="–ê—É–¥–∏–æ –∏–ª–∏ –≤–∏–¥–µ–æ —Ñ–∞–π–ª")
):
    """
    –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
    
    - **file**: –ê—É–¥–∏–æ –∏–ª–∏ –≤–∏–¥–µ–æ —Ñ–∞–π–ª (mp3, wav, m4a, mp4, avi, mov, mkv, webm, flac, ogg, wma)
    - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: 2GB
    - –¢—Ä–µ–±—É–µ—Ç—Å—è –∑–∞–≥–æ–ª–æ–≤–æ–∫ X-API-Key
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç task_id –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å–∞ –∏ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞.
    """
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞
    if not is_supported_format(file.filename):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ: {SUPPORTED_FORMATS[1]}"
        )
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º ID –∑–∞–¥–∞—á–∏
    task_id = uuid.uuid4().hex
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
    file_path = UPLOAD_DIR / f"{task_id}_{file.filename}"
    file_size = 0
    
    try:
        async with aiofiles.open(file_path, 'wb') as f:
            while chunk := await file.read(8192):
                file_size += len(chunk)
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞
                if file_size > MAX_FILE_SIZE:
                    await f.close()
                    file_path.unlink()
                    raise HTTPException(
                        status_code=status.HTTP_413_REQUEST_ENTITY_TOO_LARGE,
                        detail=f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π (–º–∞–∫—Å. {MAX_FILE_SIZE/1024/1024/1024:.1f} GB)"
                    )
                
                await f.write(chunk)
        
        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ —Ñ–∞–π–ª –ø–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–ø–∏—Å–∞–Ω –Ω–∞ –¥–∏—Å–∫
        # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É
        file_fd = os.open(str(file_path), os.O_RDONLY)
        try:
            os.fsync(file_fd)  # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª
        finally:
            os.close(file_fd)
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ –∏–º–µ–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä
        if not file_path.exists():
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="–§–∞–π–ª –Ω–µ –±—ã–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω –Ω–∞ –¥–∏—Å–∫"
            )
        
        actual_size = file_path.stat().st_size
        if actual_size != file_size:
            logger.warning(f"–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç: –æ–∂–∏–¥–∞–ª–æ—Å—å {file_size}, –ø–æ–ª—É—á–µ–Ω–æ {actual_size}")
            # –ù–µ –∫—Ä–∏—Ç–∏—á–Ω–æ, –Ω–æ –ª–æ–≥–∏—Ä—É–µ–º
    
    except Exception as e:
        if file_path.exists():
            file_path.unlink()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {str(e)}"
        )
    
    # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á—É
    tasks_storage[task_id] = {
        'task_id': task_id,
        'status': 'pending',
        'created_at': datetime.now().isoformat(),
        'started_at': None,
        'completed_at': None,
        'progress': 0,
        'filename': file.filename,
        'file_size': file_size,
        'message': '–ó–∞–¥–∞—á–∞ –≤ –æ—á–µ—Ä–µ–¥–∏ –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É'
    }
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –≤ —Ñ–æ–Ω–µ
    background_tasks.add_task(process_transcription, task_id, file_path, file.filename)
    
    logger.info(f"–°–æ–∑–¥–∞–Ω–∞ –∑–∞–¥–∞—á–∞ {task_id}: {file.filename} ({file_size/1024/1024:.1f} MB)")
    
    return UploadResponse(
        task_id=task_id,
        message="–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É",
        filename=file.filename,
        file_size=file_size,
        estimated_time="–û—Ü–µ–Ω–∫–∞ –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–∞ –ø–æ—Å–ª–µ –Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏"
    )


@app.post(
    "/api/v1/transcribe/batch",
    response_model=BatchUploadResponse,
    status_code=status.HTTP_202_ACCEPTED,
    dependencies=[Depends(verify_api_key)]
)
@limiter.limit("5/minute")  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É
async def upload_files_batch(
    request: Request,
    background_tasks: BackgroundTasks,
    files: List[UploadFile] = File(..., description="–°–ø–∏—Å–æ–∫ –∞—É–¥–∏–æ –∏–ª–∏ –≤–∏–¥–µ–æ —Ñ–∞–π–ª–æ–≤")
):
    """
    –ó–∞–≥—Ä—É–∑–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏

    - **files**: –°–ø–∏—Å–æ–∫ –∞—É–¥–∏–æ –∏–ª–∏ –≤–∏–¥–µ–æ —Ñ–∞–π–ª–æ–≤ (mp3, wav, m4a, mp4, avi, mov, mkv, webm, flac, ogg, wma)
    - –ú–∞–∫—Å–∏–º—É–º 10 —Ñ–∞–π–ª–æ–≤ –∑–∞ —Ä–∞–∑
    - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞: 2GB
    - –¢—Ä–µ–±—É–µ—Ç—Å—è –∑–∞–≥–æ–ª–æ–≤–æ–∫ X-API-Key

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ task_id –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å–∞ –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞.
    """

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ñ–∞–π–ª–æ–≤
    if len(files) > 10:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="–ú–∞–∫—Å–∏–º—É–º 10 —Ñ–∞–π–ª–æ–≤ –∑–∞ —Ä–∞–∑"
        )

    if len(files) == 0:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ñ–∞–π–ª"
        )

    uploaded_tasks = []

    for file in files:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞
        if not is_supported_format(file.filename):
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ {file.filename}. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ: {SUPPORTED_FORMATS[1]}"
            )

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º ID –∑–∞–¥–∞—á–∏
        task_id = uuid.uuid4().hex

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
        file_path = UPLOAD_DIR / f"{task_id}_{file.filename}"
        file_size = 0

        try:
            async with aiofiles.open(file_path, 'wb') as f:
                while chunk := await file.read(8192):
                    file_size += len(chunk)

                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞
                    if file_size > MAX_FILE_SIZE:
                        await f.close()
                        file_path.unlink()
                        raise HTTPException(
                            status_code=status.HTTP_413_REQUEST_ENTITY_TOO_LARGE,
                            detail=f"–§–∞–π–ª {file.filename} —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π (–º–∞–∫—Å. {MAX_FILE_SIZE/1024/1024/1024:.1f} GB)"
                        )

                    await f.write(chunk)
            
            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ —Ñ–∞–π–ª –ø–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–ø–∏—Å–∞–Ω –Ω–∞ –¥–∏—Å–∫
            # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É
            import os
            file_fd = os.open(str(file_path), os.O_RDONLY)
            try:
                os.fsync(file_fd)  # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª
            finally:
                os.close(file_fd)
            
            # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ –∏–º–µ–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä
            if not file_path.exists():
                raise HTTPException(
                    status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                    detail=f"–§–∞–π–ª {file.filename} –Ω–µ –±—ã–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω –Ω–∞ –¥–∏—Å–∫"
                )
            
            actual_size = file_path.stat().st_size
            if actual_size != file_size:
                logger.warning(f"–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ {file.filename} –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç: –æ–∂–∏–¥–∞–ª–æ—Å—å {file_size}, –ø–æ–ª—É—á–µ–Ω–æ {actual_size}")

        except Exception as e:
            if file_path.exists():
                file_path.unlink()
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file.filename}: {str(e)}"
            )

        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á—É
        tasks_storage[task_id] = {
            'task_id': task_id,
            'status': 'pending',
            'created_at': datetime.now().isoformat(),
            'started_at': None,
            'completed_at': None,
            'progress': 0,
            'filename': file.filename,
            'file_size': file_size,
            'message': '–ó–∞–¥–∞—á–∞ –≤ –æ—á–µ—Ä–µ–¥–∏ –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É'
        }

        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –≤ —Ñ–æ–Ω–µ
        background_tasks.add_task(process_transcription, task_id, file_path, file.filename)

        logger.info(f"–°–æ–∑–¥–∞–Ω–∞ –∑–∞–¥–∞—á–∞ {task_id}: {file.filename} ({file_size/1024/1024:.1f} MB)")

        uploaded_tasks.append(UploadResponse(
            task_id=task_id,
            message="–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É",
            filename=file.filename,
            file_size=file_size,
            estimated_time="–û—Ü–µ–Ω–∫–∞ –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–∞ –ø–æ—Å–ª–µ –Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏"
        ))

    return BatchUploadResponse(
        tasks=uploaded_tasks,
        total_files=len(uploaded_tasks),
        message=f"–£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(uploaded_tasks)} —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"
    )


@app.get(
    "/api/v1/tasks",
    dependencies=[Depends(verify_api_key)]
)
async def list_tasks(
    status_filter: Optional[str] = None,
    limit: int = 100
):
    """
    –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á
    
    - **status_filter**: —Ñ–∏–ª—å—Ç—Ä –ø–æ —Å—Ç–∞—Ç—É—Å—É (pending, processing, completed, failed)
    - **limit**: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 100)
    """
    tasks = list(tasks_storage.values())
    
    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è
    if status_filter:
        tasks = [t for t in tasks if t['status'] == status_filter]
    
    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –¥–∞—Ç–µ —Å–æ–∑–¥–∞–Ω–∏—è (–Ω–æ–≤—ã–µ –ø–µ—Ä–≤—ã–º–∏)
    tasks.sort(key=lambda x: x['created_at'], reverse=True)
    
    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ
    tasks = tasks[:limit]
    
    return {
        "total": len(tasks),
        "tasks": tasks
    }


@app.get(
    "/api/v1/tasks/{task_id}",
    response_model=TaskStatus,
    dependencies=[Depends(verify_api_key)]
)
async def get_task_status(task_id: str):
    """
    –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏
    
    - **task_id**: ID –∑–∞–¥–∞—á–∏, –ø–æ–ª—É—á–µ–Ω–Ω—ã–π –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞
    
    –°—Ç–∞—Ç—É—Å—ã:
    - pending: –≤ –æ—á–µ—Ä–µ–¥–∏
    - processing: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è
    - completed: –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ
    - failed: –æ—à–∏–±–∫–∞
    """
    if task_id not in tasks_storage:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="–ó–∞–¥–∞—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
        )
    
    task = tasks_storage[task_id]
    return TaskStatus(**task)


@app.get(
    "/api/v1/tasks/progress/batch",
    dependencies=[Depends(verify_api_key)]
)
async def get_batch_progress(task_ids: str):
    """
    –ü–æ–ª—É—á–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∑–∞–¥–∞—á –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
    
    - **task_ids**: –°–ø–∏—Å–æ–∫ ID –∑–∞–¥–∞—á —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é (task_id1,task_id2,task_id3)
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å –∏ –ø—Ä–æ–≥—Ä–µ—Å—Å –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏.
    –ü–æ–ª–µ–∑–Ω–æ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –≤ Postman/–∫–ª–∏–µ–Ω—Ç–µ.
    """
    # –ü–∞—Ä—Å–∏–º —Å–ø–∏—Å–æ–∫ task_id
    try:
        task_id_list = [tid.strip() for tid in task_ids.split(',') if tid.strip()]
    except:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Å–ø–∏—Å–∫–∞ task_id. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: task_id1,task_id2,task_id3"
        )
    
    if len(task_id_list) > 50:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="–ú–∞–∫—Å–∏–º—É–º 50 –∑–∞–¥–∞—á –∑–∞ —Ä–∞–∑"
        )
    
    if len(task_id_list) == 0:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω task_id. –ü–æ–ª—É—á–µ–Ω–æ: '{task_ids}'. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ task_id —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –≤ Postman –∏–ª–∏ —É–∫–∞–∂–∏—Ç–µ ID –≤—Ä—É—á–Ω—É—é."
        )
    
    # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–¥–∞—á–∞—Ö
    results = []
    not_found = []
    
    for task_id in task_id_list:
        if task_id in tasks_storage:
            task = tasks_storage[task_id]
            results.append({
                "task_id": task_id,
                "status": task['status'],
                "progress": task.get('progress', 0),
                "filename": task.get('filename', ''),
                "message": task.get('message', ''),
                "error": task.get('error')
            })
        else:
            not_found.append(task_id)
    
    return {
        "total_requested": len(task_id_list),
        "found": len(results),
        "not_found": not_found,
        "tasks": results
    }


@app.get(
    "/api/v1/tasks/{task_id}/result",
    response_model=TaskResult,
    dependencies=[Depends(verify_api_key)]
)
async def get_task_result(task_id: str):
    """
    –ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
    
    - **task_id**: ID –∑–∞–¥–∞—á–∏
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏ –∏ –±–µ–∑.
    –î–æ—Å—Ç—É–ø–Ω–æ —Ç–æ–ª—å–∫–æ –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á.
    """
    if task_id not in tasks_storage:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="–ó–∞–¥–∞—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
        )
    
    task = tasks_storage[task_id]
    
    if task['status'] != 'completed':
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"–ó–∞–¥–∞—á–∞ –µ—â–µ –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ (—Å—Ç–∞—Ç—É—Å: {task['status']})"
        )
    
    return TaskResult(
        task_id=task_id,
        status=task['status'],
        filename=task['filename'],
        transcription=task.get('transcription'),
        transcription_with_timecodes=task.get('transcription_timecoded'),
        processing_time=task.get('processing_time'),
        media_duration=task.get('media_duration')
    )


@app.get(
    "/api/v1/download-batch",
    dependencies=[Depends(verify_api_key)]
)
async def download_batch_results(task_ids: str, format: str = "txt"):
    """
    –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∑–∞–¥–∞—á –≤ ZIP –∞—Ä—Ö–∏–≤–µ

    - **task_ids**: –°–ø–∏—Å–æ–∫ ID –∑–∞–¥–∞—á —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é (task_id1,task_id2,task_id3)
    - **format**: —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–æ–≤ (txt –∏–ª–∏ timecodes)
    """

    # –ü–∞—Ä—Å–∏–º —Å–ø–∏—Å–æ–∫ task_id
    try:
        task_id_list = [tid.strip() for tid in task_ids.split(',') if tid.strip()]
    except:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Å–ø–∏—Å–∫–∞ task_id. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: task_id1,task_id2,task_id3"
        )

    if len(task_id_list) > 20:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="–ú–∞–∫—Å–∏–º—É–º 20 –∑–∞–¥–∞—á –∑–∞ —Ä–∞–∑"
        )

    if len(task_id_list) == 0:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω task_id. –ü–æ–ª—É—á–µ–Ω–æ: '{task_ids}'. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ task_id —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –≤ Postman –∏–ª–∏ —É–∫–∞–∂–∏—Ç–µ ID –≤—Ä—É—á–Ω—É—é."
        )

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏
    valid_tasks = []
    not_found_ids = []
    not_completed_ids = []
    
    for task_id in task_id_list:
        if task_id not in tasks_storage:
            not_found_ids.append(task_id)
            continue
        
        task = tasks_storage[task_id]
        if task['status'] != 'completed':
            not_completed_ids.append(f"{task_id} (status: {task['status']})")
            continue
        
        valid_tasks.append(task)
    
    if not_found_ids:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"–ó–∞–¥–∞—á–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã: {', '.join(not_found_ids)}. –í—Å–µ–≥–æ –∑–∞–¥–∞—á –≤ —Å–∏—Å—Ç–µ–º–µ: {len(tasks_storage)}. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ GET /api/v1/tasks –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö task_id."
        )
    
    if not_completed_ids:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"–ù–µ–∫–æ—Ç–æ—Ä—ã–µ –∑–∞–¥–∞—á–∏ –µ—â–µ –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω—ã: {', '.join(not_completed_ids)}"
        )

    # –°–æ–∑–¥–∞–µ–º ZIP –∞—Ä—Ö–∏–≤ –≤ –ø–∞–º—è—Ç–∏
    zip_buffer = io.BytesIO()

    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
        for task in valid_tasks:
            task_id = task['task_id']
            result_dir = RESULTS_DIR / task_id
            filename_base = Path(task['filename']).stem

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ (–±–µ–∑ task_id –ø—Ä–µ—Ñ–∏–∫—Å–∞)
            if format == "timecodes":
                file_path = result_dir / f"{filename_base}_timecodes.txt"
                zip_name = f"{filename_base}_timecodes.txt"
            else:
                file_path = result_dir / f"{filename_base}.txt"
                zip_name = f"{filename_base}.txt"

            # –õ–æ–≥–∏—Ä—É–µ–º –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            logger.debug(f"Batch download: –∏—â–µ–º —Ñ–∞–π–ª {file_path}")
            
            # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Ñ–∞–π–ª
            found_file = None
            if file_path.exists():
                found_file = file_path
                logger.debug(f"Batch download: —Ñ–∞–π–ª –Ω–∞–π–¥–µ–Ω –Ω–∞–ø—Ä—è–º—É—é {file_path}")
            else:
                # –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∞–ø—Ä—è–º—É—é, –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —á–µ—Ä–µ–∑ glob
                # –≠—Ç–æ –ø–æ–º–æ–≥–∞–µ—Ç, –µ—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π –∏–ª–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π Unicode
                logger.debug(f"Batch download: —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∞–ø—Ä—è–º—É—é, –∏—â–µ–º —á–µ—Ä–µ–∑ glob")
                
                # –ò—â–µ–º –≤—Å–µ .txt —Ñ–∞–π–ª—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
                txt_files = list(result_dir.glob("*.txt"))
                logger.debug(f"Batch download: –Ω–∞–π–¥–µ–Ω–æ .txt —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {len(txt_files)}")
                
                # –ò—â–µ–º —Ñ–∞–π–ª –ø–æ –±–∞–∑–æ–≤–æ–º—É –∏–º–µ–Ω–∏ (–±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è)
                for txt_file in txt_files:
                    file_stem = txt_file.stem
                    # –£–±–∏—Ä–∞–µ–º _timecodes –∏–∑ –∏–º–µ–Ω–∏, –µ—Å–ª–∏ —ç—Ç–æ —Ñ–∞–π–ª —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏
                    if file_stem.endswith("_timecodes"):
                        file_stem = file_stem[:-10]  # –£–±–∏—Ä–∞–µ–º "_timecodes"
                    
                    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –±–∞–∑–æ–≤–æ–µ –∏–º—è
                    if file_stem == filename_base:
                        found_file = txt_file
                        logger.debug(f"Batch download: —Ñ–∞–π–ª –Ω–∞–π–¥–µ–Ω —á–µ—Ä–µ–∑ glob: {txt_file}")
                        break
                
                # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ –∏–º–µ–Ω–∏, –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É
                if not found_file:
                    pattern_files = list(result_dir.glob(f"*{filename_base}*"))
                    if pattern_files:
                        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –ø–æ–¥—Ö–æ–¥—è—â–∏–π —Ñ–∞–π–ª
                        for pf in pattern_files:
                            if pf.suffix == ".txt":
                                if format == "timecodes" and "_timecodes" in pf.name:
                                    found_file = pf
                                    break
                                elif format != "timecodes" and "_timecodes" not in pf.name:
                                    found_file = pf
                                    break
                        
                        if found_file:
                            logger.debug(f"Batch download: —Ñ–∞–π–ª –Ω–∞–π–¥–µ–Ω –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É: {found_file}")
            
            if found_file and found_file.exists():
                try:
                    zip_file.write(found_file, zip_name)
                    logger.debug(f"Batch download: –¥–æ–±–∞–≤–ª–µ–Ω —Ñ–∞–π–ª {zip_name} –∏–∑ {found_file}")
                except Exception as e:
                    logger.error(f"Batch download: –æ—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {found_file}: {e}")
                    error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {str(e)}"
                    zip_file.writestr(zip_name, error_msg)
            else:
                # –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª —Å —Å–æ–æ–±—â–µ–Ω–∏–µ–º
                error_msg = f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è —Ñ–∞–π–ª–∞ {task['filename']} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã\n"
                error_msg += f"–ò—Å–∫–∞–ª–∏: {file_path}\n"
                error_msg += f"–ü–∞–ø–∫–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {result_dir.exists()}\n"
                if result_dir.exists():
                    all_files = list(result_dir.iterdir())
                    error_msg += f"–§–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ: {all_files}\n"
                    error_msg += f"–ë–∞–∑–æ–≤–æ–µ –∏–º—è —Ñ–∞–π–ª–∞: {filename_base}\n"
                    error_msg += f"–§–æ—Ä–º–∞—Ç: {format}"
                zip_file.writestr(zip_name, error_msg)
                logger.warning(f"Batch download: —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω {file_path}")

    zip_buffer.seek(0)

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º ZIP —Ñ–∞–π–ª
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"transcription_results_{timestamp}.zip"

    return StreamingResponse(
        iter([zip_buffer.getvalue()]),
        media_type="application/zip",
        headers={"Content-Disposition": f"attachment; filename={filename}"}
    )


@app.get(
    "/api/v1/tasks/{task_id}/download",
    dependencies=[Depends(verify_api_key)]
)
async def download_result(task_id: str, format: str = "txt"):
    """
    –°–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    
    - **task_id**: ID –∑–∞–¥–∞—á–∏
    - **format**: —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ (txt –∏–ª–∏ timecodes)
    """
    if task_id not in tasks_storage:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="–ó–∞–¥–∞—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
        )
    
    task = tasks_storage[task_id]
    
    if task['status'] != 'completed':
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"–ó–∞–¥–∞—á–∞ –µ—â–µ –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ (—Å—Ç–∞—Ç—É—Å: {task['status']})"
        )
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–∞–π–ª
    result_dir = RESULTS_DIR / task_id
    filename_base = Path(task['filename']).stem
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ (–±–µ–∑ task_id –ø—Ä–µ—Ñ–∏–∫—Å–∞)
    if format == "timecodes":
        file_path = result_dir / f"{filename_base}_timecodes.txt"
    else:
        file_path = result_dir / f"{filename_base}.txt"
    
    # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Ñ–∞–π–ª
    found_file = None
    if file_path.exists():
        found_file = file_path
    else:
        # –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∞–ø—Ä—è–º—É—é, –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —á–µ—Ä–µ–∑ glob
        logger.debug(f"Download: —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∞–ø—Ä—è–º—É—é {file_path}, –∏—â–µ–º —á–µ—Ä–µ–∑ glob")
        
        # –ò—â–µ–º –≤—Å–µ .txt —Ñ–∞–π–ª—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        txt_files = list(result_dir.glob("*.txt"))
        
        # –ò—â–µ–º —Ñ–∞–π–ª –ø–æ –±–∞–∑–æ–≤–æ–º—É –∏–º–µ–Ω–∏
        for txt_file in txt_files:
            file_stem = txt_file.stem
            # –£–±–∏—Ä–∞–µ–º _timecodes –∏–∑ –∏–º–µ–Ω–∏, –µ—Å–ª–∏ —ç—Ç–æ —Ñ–∞–π–ª —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏
            if file_stem.endswith("_timecodes"):
                file_stem = file_stem[:-10]
            
            # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –±–∞–∑–æ–≤–æ–µ –∏–º—è
            if file_stem == filename_base:
                if format == "timecodes" and "_timecodes" in txt_file.name:
                    found_file = txt_file
                    break
                elif format != "timecodes" and "_timecodes" not in txt_file.name:
                    found_file = txt_file
                    break
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ –∏–º–µ–Ω–∏, –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É
        if not found_file:
            pattern_files = list(result_dir.glob(f"*{filename_base}*"))
            for pf in pattern_files:
                if pf.suffix == ".txt":
                    if format == "timecodes" and "_timecodes" in pf.name:
                        found_file = pf
                        break
                    elif format != "timecodes" and "_timecodes" not in pf.name:
                        found_file = pf
                        break
    
    if not found_file or not found_file.exists():
        error_detail = f"–§–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω. –ò—Å–∫–∞–ª–∏: {file_path}"
        if result_dir.exists():
            all_files = list(result_dir.iterdir())
            error_detail += f". –§–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ: {all_files}"
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=error_detail
        )
    
    return FileResponse(
        path=found_file,
        filename=found_file.name,
        media_type="text/plain"
    )


@app.delete(
    "/api/v1/tasks/{task_id}",
    dependencies=[Depends(verify_api_key)]
)
async def delete_task(task_id: str):
    """
    –£–¥–∞–ª–∏—Ç—å –∑–∞–¥–∞—á—É –∏ —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    
    - **task_id**: ID –∑–∞–¥–∞—á–∏
    """
    if task_id not in tasks_storage:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="–ó–∞–¥–∞—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
        )
    
    task = tasks_storage[task_id]
    
    if task['status'] == 'processing':
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="–ù–µ–ª—å–∑—è —É–¥–∞–ª–∏—Ç—å –∑–∞–¥–∞—á—É –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏"
        )
    
    # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª—ã
    upload_path = UPLOAD_DIR / f"{task_id}_{task['filename']}"
    if upload_path.exists():
        upload_path.unlink()
    
    result_dir = RESULTS_DIR / task_id
    if result_dir.exists():
        shutil.rmtree(result_dir)
    
    # –£–¥–∞–ª—è–µ–º –∑–∞–¥–∞—á—É
    del tasks_storage[task_id]
    
    logger.info(f"–ó–∞–¥–∞—á–∞ {task_id} —É–¥–∞–ª–µ–Ω–∞")
    
    return {"message": "–ó–∞–¥–∞—á–∞ —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω–∞"}


@app.delete(
    "/api/v1/tasks",
    dependencies=[Depends(verify_api_key)]
)
async def delete_all_tasks(status_filter: Optional[str] = None):
    """
    –£–¥–∞–ª–∏—Ç—å –≤—Å–µ –∑–∞–¥–∞—á–∏ (–º–∞—Å—Å–æ–≤–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ)
    
    - **status_filter**: —Ñ–∏–ª—å—Ç—Ä –ø–æ —Å—Ç–∞—Ç—É—Å—É –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è (completed, failed, pending, all)
      - –ï—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —É–¥–∞–ª—è—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏ (completed, failed)
      - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ "all" –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –≤—Å–µ—Ö –∑–∞–¥–∞—á –≤–∫–ª—é—á–∞—è pending
      - –ó–∞–¥–∞—á–∏ —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º "processing" –ù–ò–ö–û–ì–î–ê –Ω–µ —É–¥–∞–ª—è—é—Ç—Å—è
    
    –ü—Ä–∏–º–µ—Ä—ã:
    - DELETE /api/v1/tasks - —É–¥–∞–ª–∏—Ç –≤—Å–µ completed –∏ failed –∑–∞–¥–∞—á–∏
    - DELETE /api/v1/tasks?status_filter=completed - —É–¥–∞–ª–∏—Ç —Ç–æ–ª—å–∫–æ completed
    - DELETE /api/v1/tasks?status_filter=all - —É–¥–∞–ª–∏—Ç –≤—Å–µ –∫—Ä–æ–º–µ processing
    """
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫–∏–µ —Å—Ç–∞—Ç—É—Å—ã —É–¥–∞–ª—è—Ç—å
    if status_filter == "all":
        # –£–¥–∞–ª—è–µ–º –≤—Å–µ –∫—Ä–æ–º–µ processing
        statuses_to_delete = ['pending', 'completed', 'failed']
    elif status_filter in ['completed', 'failed', 'pending']:
        # –£–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ —É–∫–∞–∑–∞–Ω–Ω—ã–π —Å—Ç–∞—Ç—É—Å
        statuses_to_delete = [status_filter]
    elif status_filter is None:
        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —É–¥–∞–ª—è–µ–º completed –∏ failed
        statuses_to_delete = ['completed', 'failed']
    else:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"–ù–µ–≤–µ—Ä–Ω—ã–π —Å—Ç–∞—Ç—É—Å —Ñ–∏–ª—å—Ç—Ä–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: completed, failed, pending, all"
        )
    
    # –°–æ–±–∏—Ä–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
    tasks_to_delete = []
    for task_id, task in tasks_storage.items():
        if task['status'] in statuses_to_delete:
            tasks_to_delete.append(task_id)
    
    if len(tasks_to_delete) == 0:
        return {
            "message": "–ù–µ—Ç –∑–∞–¥–∞—á –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è",
            "deleted_count": 0,
            "filter": status_filter or "completed, failed (default)"
        }
    
    # –£–¥–∞–ª—è–µ–º –∑–∞–¥–∞—á–∏ –∏ –∏—Ö —Ñ–∞–π–ª—ã
    deleted_count = 0
    errors = []
    
    for task_id in tasks_to_delete:
        try:
            task = tasks_storage[task_id]
            
            # –£–¥–∞–ª—è–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            upload_path = UPLOAD_DIR / f"{task_id}_{task['filename']}"
            if upload_path.exists():
                upload_path.unlink()
            
            # –£–¥–∞–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            result_dir = RESULTS_DIR / task_id
            if result_dir.exists():
                shutil.rmtree(result_dir)
            
            # –£–¥–∞–ª—è–µ–º –∏–∑ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
            del tasks_storage[task_id]
            deleted_count += 1
            
        except Exception as e:
            errors.append(f"{task_id}: {str(e)}")
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –∑–∞–¥–∞—á–∏ {task_id}: {str(e)}")
    
    logger.info(f"–ú–∞—Å—Å–æ–≤–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ: —É–¥–∞–ª–µ–Ω–æ {deleted_count} –∑–∞–¥–∞—á (—Ñ–∏–ª—å—Ç—Ä: {status_filter or 'default'})")
    
    response = {
        "message": f"–£—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω–æ –∑–∞–¥–∞—á: {deleted_count}",
        "deleted_count": deleted_count,
        "filter": status_filter or "completed, failed (default)"
    }
    
    if errors:
        response["errors"] = errors
        response["message"] += f" (—Å –æ—à–∏–±–∫–∞–º–∏: {len(errors)})"
    
    return response


# ==================== –ó–ê–ü–£–°–ö ====================

if __name__ == "__main__":
    import uvicorn
    
    uvicorn.run(
        "api:app",
        host=API_HOST,
        port=API_PORT,
        reload=False,
        log_level="info"
    )


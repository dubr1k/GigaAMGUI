#!/usr/bin/env python3
"""
GigaAM v3 Transcriber - REST API
–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π REST API –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ —Å –¥–æ—Å—Ç—É–ø–æ–º –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞
"""

import os
import sys
import uuid
import time
import asyncio
import shutil
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional, List, Dict
from contextlib import asynccontextmanager

import aiofiles
from fastapi import (
    FastAPI, File, UploadFile, HTTPException, Depends,
    BackgroundTasks, status, Header, Request
)
from fastapi.responses import JSONResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

# –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
import warnings
warnings.filterwarnings("ignore", category=UserWarning)

# –ò–º–ø–æ—Ä—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞
from src.utils.pyannote_patch import apply_pyannote_patch
from src.core.model_loader import ModelLoader
from src.core.processor import TranscriptionProcessor
from src.utils.processing_stats import ProcessingStats
from src.utils.logger import setup_logger
from src.config import HF_TOKEN, SUPPORTED_FORMATS

# –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–∞—Ç—á
apply_pyannote_patch()

# ==================== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ====================

# API –∫–ª—é—á–∏ (–≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å .env –∏–ª–∏ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö)
API_KEYS_FILE = Path(__file__).parent / ".api_keys"
VALID_API_KEYS = set()

# –î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
UPLOAD_DIR = Path(__file__).parent / "uploads"
RESULTS_DIR = Path(__file__).parent / "results"
UPLOAD_DIR.mkdir(exist_ok=True)
RESULTS_DIR.mkdir(exist_ok=True)

# –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
MAX_FILE_SIZE = 2 * 1024 * 1024 * 1024  # 2GB
MAX_CONCURRENT_TASKS = 3
TASK_CLEANUP_HOURS = 24

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
model_loader = None
stats_manager = None
logger = None

# –•—Ä–∞–Ω–∏–ª–∏—â–µ –∑–∞–¥–∞—á (–≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Redis –∏–ª–∏ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö)
tasks_storage: Dict[str, dict] = {}

# –°–µ–º–∞—Ñ–æ—Ä –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á
processing_semaphore = None


# ==================== –ú–û–î–ï–õ–ò ====================

class TaskStatus(BaseModel):
    """–°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏"""
    task_id: str
    status: str  # pending, processing, completed, failed
    created_at: str
    started_at: Optional[str] = None
    completed_at: Optional[str] = None
    progress: int = 0  # 0-100
    filename: str
    file_size: int
    message: Optional[str] = None
    error: Optional[str] = None


class TaskResult(BaseModel):
    """–†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏"""
    task_id: str
    status: str
    filename: str
    transcription: Optional[str] = None
    transcription_with_timecodes: Optional[str] = None
    processing_time: Optional[float] = None
    media_duration: Optional[float] = None


class UploadResponse(BaseModel):
    """–û—Ç–≤–µ—Ç –Ω–∞ –∑–∞–≥—Ä—É–∑–∫—É —Ñ–∞–π–ª–∞"""
    task_id: str
    message: str
    filename: str
    file_size: int
    estimated_time: Optional[str] = None


class APIKeyCreate(BaseModel):
    """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ API –∫–ª—é—á–∞"""
    description: str = Field(..., min_length=3, max_length=100)


class APIKeyResponse(BaseModel):
    """–û—Ç–≤–µ—Ç —Å API –∫–ª—é—á–æ–º"""
    api_key: str
    description: str
    created_at: str


# ==================== –£–¢–ò–õ–ò–¢–´ ====================

def load_api_keys():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç API –∫–ª—é—á–∏ –∏–∑ —Ñ–∞–π–ª–∞"""
    global VALID_API_KEYS
    if API_KEYS_FILE.exists():
        with open(API_KEYS_FILE, 'r') as f:
            VALID_API_KEYS = set(line.strip() for line in f if line.strip())
    else:
        # –°–æ–∑–¥–∞–µ–º –ø–µ—Ä–≤—ã–π –∫–ª—é—á –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        default_key = f"gam_{uuid.uuid4().hex}"
        VALID_API_KEYS.add(default_key)
        save_api_keys()
        print(f"\n{'='*60}")
        print(f"–ü–ï–†–í–´–ô API –ö–õ–Æ–ß –°–û–ó–î–ê–ù:")
        print(f"  {default_key}")
        print(f"–°–æ—Ö—Ä–∞–Ω–∏—Ç–µ –µ–≥–æ –≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ–º –º–µ—Å—Ç–µ!")
        print(f"{'='*60}\n")


def save_api_keys():
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç API –∫–ª—é—á–∏ –≤ —Ñ–∞–π–ª"""
    with open(API_KEYS_FILE, 'w') as f:
        for key in VALID_API_KEYS:
            f.write(f"{key}\n")
    os.chmod(API_KEYS_FILE, 0o600)  # –¢–æ–ª—å–∫–æ –≤–ª–∞–¥–µ–ª–µ—Ü –º–æ–∂–µ—Ç —á–∏—Ç–∞—Ç—å


def verify_api_key(x_api_key: str = Header(..., alias="X-API-Key")) -> str:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç API –∫–ª—é—á"""
    if x_api_key not in VALID_API_KEYS:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="–ù–µ–≤–µ—Ä–Ω—ã–π API –∫–ª—é—á"
        )
    return x_api_key


def is_supported_format(filename: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞"""
    extensions = SUPPORTED_FORMATS[1].split()
    file_ext = Path(filename).suffix.lower()
    return any(file_ext == ext.replace('*', '') for ext in extensions)


async def cleanup_old_tasks():
    """–û—á–∏—â–∞–µ—Ç —Å—Ç–∞—Ä—ã–µ –∑–∞–¥–∞—á–∏ –∏ —Ñ–∞–π–ª—ã"""
    now = time.time()
    cutoff = now - (TASK_CLEANUP_HOURS * 3600)
    
    tasks_to_remove = []
    for task_id, task in tasks_storage.items():
        created_timestamp = datetime.fromisoformat(task['created_at']).timestamp()
        if created_timestamp < cutoff:
            tasks_to_remove.append(task_id)
            
            # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª—ã
            upload_path = UPLOAD_DIR / f"{task_id}_{task['filename']}"
            if upload_path.exists():
                upload_path.unlink()
            
            # –£–¥–∞–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            result_dir = RESULTS_DIR / task_id
            if result_dir.exists():
                shutil.rmtree(result_dir)
    
    for task_id in tasks_to_remove:
        del tasks_storage[task_id]
        logger.info(f"–û—á–∏—â–µ–Ω–∞ –∑–∞–¥–∞—á–∞ {task_id} (—Å—Ç–∞—Ä—à–µ {TASK_CLEANUP_HOURS}—á)")


async def process_transcription(task_id: str, file_path: Path, filename: str):
    """
    –§–æ–Ω–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
    
    Args:
        task_id: ID –∑–∞–¥–∞—á–∏
        file_path: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
        filename: –∏–º—è —Ñ–∞–π–ª–∞
    """
    async with processing_semaphore:
        try:
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
            tasks_storage[task_id]['status'] = 'processing'
            tasks_storage[task_id]['started_at'] = datetime.now().isoformat()
            tasks_storage[task_id]['progress'] = 5
            
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            output_dir = RESULTS_DIR / task_id
            output_dir.mkdir(exist_ok=True)
            
            # Callback –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            def progress_callback(stage: str, progress: float):
                if stage == 'conversion':
                    tasks_storage[task_id]['progress'] = int(5 + progress * 15)
                elif stage == 'transcription':
                    tasks_storage[task_id]['progress'] = int(20 + progress * 75)
            
            # –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä
            processor = TranscriptionProcessor(
                model_loader=model_loader,
                stats_manager=stats_manager,
                logger=lambda msg: logger.debug(f"[{task_id}] {msg}"),
                progress_callback=progress_callback
            )
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–º –∫–æ–¥–µ —á–µ—Ä–µ–∑ executor
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(
                None,
                processor.process_file,
                str(file_path),
                str(output_dir),
                0,
                1
            )
            
            if result['success']:
                # –ß–∏—Ç–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                text_file = output_dir / f"{Path(filename).stem}.txt"
                timecode_file = output_dir / f"{Path(filename).stem}_timecodes.txt"
                
                transcription = ""
                transcription_timecoded = ""
                
                if text_file.exists():
                    async with aiofiles.open(text_file, 'r', encoding='utf-8') as f:
                        transcription = await f.read()
                
                if timecode_file.exists():
                    async with aiofiles.open(timecode_file, 'r', encoding='utf-8') as f:
                        transcription_timecoded = await f.read()
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–¥–∞—á—É
                tasks_storage[task_id].update({
                    'status': 'completed',
                    'completed_at': datetime.now().isoformat(),
                    'progress': 100,
                    'transcription': transcription,
                    'transcription_timecoded': transcription_timecoded,
                    'processing_time': result['total_time'],
                    'media_duration': result.get('media_duration', 0),
                    'message': '–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞'
                })
                
                logger.info(f"–ó–∞–¥–∞—á–∞ {task_id} —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ ({result['total_time']:.1f}—Å)")
                
            else:
                raise Exception("–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–¥–∞—á–∏ {task_id}: {str(e)}")
            tasks_storage[task_id].update({
                'status': 'failed',
                'completed_at': datetime.now().isoformat(),
                'error': str(e),
                'message': f'–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}'
            })
        
        finally:
            # –£–¥–∞–ª—è–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            if file_path.exists():
                file_path.unlink()


# ==================== LIFESPAN ====================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    global model_loader, stats_manager, logger, processing_semaphore
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    print("="*60)
    print("üöÄ –ó–∞–ø—É—Å–∫ GigaAM v3 Transcriber API")
    print("="*60)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ API –∫–ª—é—á–µ–π
    load_api_keys()
    
    # –õ–æ–≥–≥–µ—Ä
    logger = setup_logger()
    logger.info("API —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è...")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–∫–µ–Ω–∞
    if not HF_TOKEN or not HF_TOKEN.startswith("hf_"):
        logger.error("HuggingFace —Ç–æ–∫–µ–Ω –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω!")
        raise RuntimeError("–¢—Ä–µ–±—É–µ—Ç—Å—è –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å HF_TOKEN –≤ .env")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ GigaAM-v3...")
    model_loader = ModelLoader()
    success = model_loader.load_model(logger=logger.info)
    
    if not success:
        logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å!")
        raise RuntimeError("–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏")
    
    logger.info("–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats_manager = ProcessingStats()
    
    # –°–µ–º–∞—Ñ–æ—Ä –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∑–∞–¥–∞—á
    processing_semaphore = asyncio.Semaphore(MAX_CONCURRENT_TASKS)
    
    logger.info(f"API –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ (–º–∞–∫—Å. {MAX_CONCURRENT_TASKS} –∑–∞–¥–∞—á –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ)")
    print("‚úÖ API —Å–µ—Ä–≤–µ—Ä —É—Å–ø–µ—à–Ω–æ –∑–∞–ø—É—â–µ–Ω!")
    print("="*60)
    
    yield
    
    # –û—á–∏—Å—Ç–∫–∞
    logger.info("–û—Å—Ç–∞–Ω–æ–≤–∫–∞ API —Å–µ—Ä–≤–µ—Ä–∞...")
    print("\nüëã API —Å–µ—Ä–≤–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")


# ==================== –ü–†–ò–õ–û–ñ–ï–ù–ò–ï ====================

# Rate limiter
limiter = Limiter(key_func=get_remote_address)

app = FastAPI(
    title="GigaAM v3 Transcriber API",
    description="REST API –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –∞—É–¥–∏–æ –∏ –≤–∏–¥–µ–æ —Ñ–∞–π–ª–æ–≤ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ",
    version="3.0.0",
    lifespan=lifespan
)

app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # –í –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ —É–∫–∞–∑–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–æ–º–µ–Ω—ã
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ==================== –≠–ù–î–ü–û–ò–ù–¢–´ ====================

@app.get("/")
async def root():
    """–ö–æ—Ä–Ω–µ–≤–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç"""
    return {
        "service": "GigaAM v3 Transcriber API",
        "version": "3.0.0",
        "status": "running",
        "endpoints": {
            "health": "/health",
            "upload": "/api/v1/transcribe",
            "status": "/api/v1/tasks/{task_id}",
            "result": "/api/v1/tasks/{task_id}/result",
            "download": "/api/v1/tasks/{task_id}/download",
            "tasks": "/api/v1/tasks",
            "docs": "/docs"
        }
    }


@app.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞"""
    return {
        "status": "healthy",
        "model_loaded": model_loader is not None and model_loader.is_loaded(),
        "active_tasks": sum(1 for t in tasks_storage.values() if t['status'] == 'processing'),
        "total_tasks": len(tasks_storage),
        "uptime": "running"
    }


@app.post(
    "/api/v1/transcribe",
    response_model=UploadResponse,
    status_code=status.HTTP_202_ACCEPTED,
    dependencies=[Depends(verify_api_key)]
)
@limiter.limit("10/minute")
async def upload_file(
    request: Request,
    background_tasks: BackgroundTasks,
    file: UploadFile = File(..., description="–ê—É–¥–∏–æ –∏–ª–∏ –≤–∏–¥–µ–æ —Ñ–∞–π–ª")
):
    """
    –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
    
    - **file**: –ê—É–¥–∏–æ –∏–ª–∏ –≤–∏–¥–µ–æ —Ñ–∞–π–ª (mp3, wav, m4a, mp4, avi, mov, mkv, webm, flac, ogg, wma)
    - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: 2GB
    - –¢—Ä–µ–±—É–µ—Ç—Å—è –∑–∞–≥–æ–ª–æ–≤–æ–∫ X-API-Key
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç task_id –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å–∞ –∏ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞.
    """
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞
    if not is_supported_format(file.filename):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ: {SUPPORTED_FORMATS[1]}"
        )
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º ID –∑–∞–¥–∞—á–∏
    task_id = uuid.uuid4().hex
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
    file_path = UPLOAD_DIR / f"{task_id}_{file.filename}"
    file_size = 0
    
    try:
        async with aiofiles.open(file_path, 'wb') as f:
            while chunk := await file.read(8192):
                file_size += len(chunk)
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞
                if file_size > MAX_FILE_SIZE:
                    await f.close()
                    file_path.unlink()
                    raise HTTPException(
                        status_code=status.HTTP_413_REQUEST_ENTITY_TOO_LARGE,
                        detail=f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π (–º–∞–∫—Å. {MAX_FILE_SIZE/1024/1024/1024:.1f} GB)"
                    )
                
                await f.write(chunk)
    
    except Exception as e:
        if file_path.exists():
            file_path.unlink()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {str(e)}"
        )
    
    # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á—É
    tasks_storage[task_id] = {
        'task_id': task_id,
        'status': 'pending',
        'created_at': datetime.now().isoformat(),
        'started_at': None,
        'completed_at': None,
        'progress': 0,
        'filename': file.filename,
        'file_size': file_size,
        'message': '–ó–∞–¥–∞—á–∞ –≤ –æ—á–µ—Ä–µ–¥–∏ –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É'
    }
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –≤ —Ñ–æ–Ω–µ
    background_tasks.add_task(process_transcription, task_id, file_path, file.filename)
    
    logger.info(f"–°–æ–∑–¥–∞–Ω–∞ –∑–∞–¥–∞—á–∞ {task_id}: {file.filename} ({file_size/1024/1024:.1f} MB)")
    
    return UploadResponse(
        task_id=task_id,
        message="–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É",
        filename=file.filename,
        file_size=file_size,
        estimated_time="–û—Ü–µ–Ω–∫–∞ –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–∞ –ø–æ—Å–ª–µ –Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏"
    )


@app.get(
    "/api/v1/tasks/{task_id}",
    response_model=TaskStatus,
    dependencies=[Depends(verify_api_key)]
)
async def get_task_status(task_id: str):
    """
    –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏
    
    - **task_id**: ID –∑–∞–¥–∞—á–∏, –ø–æ–ª—É—á–µ–Ω–Ω—ã–π –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞
    
    –°—Ç–∞—Ç—É—Å—ã:
    - pending: –≤ –æ—á–µ—Ä–µ–¥–∏
    - processing: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è
    - completed: –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ
    - failed: –æ—à–∏–±–∫–∞
    """
    if task_id not in tasks_storage:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="–ó–∞–¥–∞—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
        )
    
    task = tasks_storage[task_id]
    return TaskStatus(**task)


@app.get(
    "/api/v1/tasks/{task_id}/result",
    response_model=TaskResult,
    dependencies=[Depends(verify_api_key)]
)
async def get_task_result(task_id: str):
    """
    –ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
    
    - **task_id**: ID –∑–∞–¥–∞—á–∏
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏ –∏ –±–µ–∑.
    –î–æ—Å—Ç—É–ø–Ω–æ —Ç–æ–ª—å–∫–æ –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á.
    """
    if task_id not in tasks_storage:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="–ó–∞–¥–∞—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
        )
    
    task = tasks_storage[task_id]
    
    if task['status'] != 'completed':
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"–ó–∞–¥–∞—á–∞ –µ—â–µ –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ (—Å—Ç–∞—Ç—É—Å: {task['status']})"
        )
    
    return TaskResult(
        task_id=task_id,
        status=task['status'],
        filename=task['filename'],
        transcription=task.get('transcription'),
        transcription_with_timecodes=task.get('transcription_timecoded'),
        processing_time=task.get('processing_time'),
        media_duration=task.get('media_duration')
    )


@app.get(
    "/api/v1/tasks/{task_id}/download",
    dependencies=[Depends(verify_api_key)]
)
async def download_result(task_id: str, format: str = "txt"):
    """
    –°–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    
    - **task_id**: ID –∑–∞–¥–∞—á–∏
    - **format**: —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ (txt –∏–ª–∏ timecodes)
    """
    if task_id not in tasks_storage:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="–ó–∞–¥–∞—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
        )
    
    task = tasks_storage[task_id]
    
    if task['status'] != 'completed':
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"–ó–∞–¥–∞—á–∞ –µ—â–µ –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ (—Å—Ç–∞—Ç—É—Å: {task['status']})"
        )
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–∞–π–ª
    result_dir = RESULTS_DIR / task_id
    filename_base = Path(task['filename']).stem
    
    if format == "timecodes":
        file_path = result_dir / f"{filename_base}_timecodes.txt"
    else:
        file_path = result_dir / f"{filename_base}.txt"
    
    if not file_path.exists():
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="–§–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω"
        )
    
    return FileResponse(
        path=file_path,
        filename=file_path.name,
        media_type="text/plain"
    )


@app.get(
    "/api/v1/tasks",
    dependencies=[Depends(verify_api_key)]
)
async def list_tasks(
    status_filter: Optional[str] = None,
    limit: int = 100
):
    """
    –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á
    
    - **status_filter**: —Ñ–∏–ª—å—Ç—Ä –ø–æ —Å—Ç–∞—Ç—É—Å—É (pending, processing, completed, failed)
    - **limit**: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 100)
    """
    tasks = list(tasks_storage.values())
    
    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è
    if status_filter:
        tasks = [t for t in tasks if t['status'] == status_filter]
    
    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –¥–∞—Ç–µ —Å–æ–∑–¥–∞–Ω–∏—è (–Ω–æ–≤—ã–µ –ø–µ—Ä–≤—ã–º–∏)
    tasks.sort(key=lambda x: x['created_at'], reverse=True)
    
    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ
    tasks = tasks[:limit]
    
    return {
        "total": len(tasks),
        "tasks": tasks
    }


@app.delete(
    "/api/v1/tasks/{task_id}",
    dependencies=[Depends(verify_api_key)]
)
async def delete_task(task_id: str):
    """
    –£–¥–∞–ª–∏—Ç—å –∑–∞–¥–∞—á—É –∏ —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    
    - **task_id**: ID –∑–∞–¥–∞—á–∏
    """
    if task_id not in tasks_storage:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="–ó–∞–¥–∞—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
        )
    
    task = tasks_storage[task_id]
    
    if task['status'] == 'processing':
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="–ù–µ–ª—å–∑—è —É–¥–∞–ª–∏—Ç—å –∑–∞–¥–∞—á—É –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏"
        )
    
    # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª—ã
    upload_path = UPLOAD_DIR / f"{task_id}_{task['filename']}"
    if upload_path.exists():
        upload_path.unlink()
    
    result_dir = RESULTS_DIR / task_id
    if result_dir.exists():
        shutil.rmtree(result_dir)
    
    # –£–¥–∞–ª—è–µ–º –∑–∞–¥–∞—á—É
    del tasks_storage[task_id]
    
    logger.info(f"–ó–∞–¥–∞—á–∞ {task_id} —É–¥–∞–ª–µ–Ω–∞")
    
    return {"message": "–ó–∞–¥–∞—á–∞ —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω–∞"}


# ==================== –ó–ê–ü–£–°–ö ====================

if __name__ == "__main__":
    import uvicorn
    
    uvicorn.run(
        "api:app",
        host="127.0.0.1",
        port=8000,
        reload=False,
        log_level="info"
    )

